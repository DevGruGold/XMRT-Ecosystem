services:
  # Main XMRT Eliza Orchestrator - Production AI Assistant
  - type: web
    name: xmrt-eliza-production
    env: python
    region: oregon # Matched to other services for low latency
    plan: professional
    # THE FIX: Use the unified requirements file
    buildCommand: "pip install -r requirements.txt"
    startCommand: |
      export ELIZA_MODE=PRODUCTION_WORKER
      export AI_OPTIMIZATION_LEVEL=MAXIMUM
      python advanced_eliza_orchestrator.py
    healthCheckPath: /health
    branch: main
    autoDeploy: true
    scaling:
      minInstances: 2
      maxInstances: 8
      targetCPUPercent: 65
      targetMemoryPercent: 75
    envVars:
      - key: OPENAI_API_KEY
        sync: false # Set as a secret in the dashboard
      - key: WEB3_RPC_URL
        sync: false # Add this secret in the dashboard
      - key: FLASK_ENV
        value: production
      - key: PYTHONUNBUFFERED
        value: "1"
      # --- All of your custom environment variables are preserved ---
      - key: ELIZA_WORK_MODE
        value: ACTIVE_PRODUCTION
      - key: AI_PROCESSING_PRIORITY
        value: HIGH
      - key: CONVERSATION_DEPTH
        value: ADVANCED
      - key: RESPONSE_INTELLIGENCE
        value: MAXIMUM
      - key: LEARNING_ENABLED
        value: "true"
      - key: PRODUCTIVITY_METRICS
        value: "true"
      - key: REAL_TIME_OPTIMIZATION
        value: "true"
      - key: AI_MODEL_NAME
        value: gpt-4-turbo-preview
      - key: MAX_TOKENS
        value: "500"
      - key: AI_TEMPERATURE
        value: "0.6"
      - key: CONVERSATION_MEMORY_DEPTH
        value: "50"
      - key: SESSION_INTELLIGENCE
        value: "true"
      - key: CONTEXT_AWARENESS_LEVEL
        value: "DEEP"
      - key: MULTI_TURN_REASONING
        value: "true"
      - key: ADAPTIVE_RESPONSES
        value: "true"
      - key: PERFORMANCE_MONITORING
        value: "CONTINUOUS"
      - key: ERROR_RECOVERY_MODE
        value: "INTELLIGENT"
      - key: LOAD_BALANCING
        value: "DYNAMIC"
      - key: CACHE_OPTIMIZATION
        value: "AGGRESSIVE"
      - key: RESPONSE_CACHING
        value: "SMART"
      - key: CONVERSATION_ANALYTICS
        value: "ENABLED"
      - key: USER_BEHAVIOR_LEARNING
        value: "ACTIVE"
      - key: PREDICTIVE_RESPONSES
        value: "true"
      - key: CONTEXT_RETENTION
        value: "ENHANCED"
      - key: KNOWLEDGE_BASE_ACCESS
        value: "FULL"
      - key: REASONING_DEPTH
        value: "COMPREHENSIVE"
      - key: CREATIVE_THINKING_MODE
        value: "ENABLED"
      - key: PROBLEM_SOLVING_LEVEL
        value: "EXPERT"
      - key: TECHNICAL_EXPERTISE
        value: "ADVANCED"
      - key: XMRT_ECOSYSTEM_KNOWLEDGE
        value: "SPECIALIZED"
      - key: BLOCKCHAIN_INTELLIGENCE
        value: "EXPERT"
      - key: DAO_GOVERNANCE_EXPERTISE
        value: "ADVANCED"
      - key: AI_SELF_IMPROVEMENT
        value: "CONTINUOUS"
      - key: PERFORMANCE_OPTIMIZATION
        value: "REAL_TIME"
      - key: WORKLOAD_DISTRIBUTION
        value: "INTELLIGENT"
      - key: RESOURCE_MANAGEMENT
        value: "OPTIMIZED"
      - key: SCALABILITY_MODE
        value: "DYNAMIC"
      - key: AVAILABILITY_TARGET
        value: "99.9"
      - key: RESPONSE_TIME_TARGET
        value: "200ms"
      - key: CONCURRENT_USERS_TARGET
        value: "1000"
      - key: THROUGHPUT_OPTIMIZATION
        value: "MAXIMUM"

  # Dedicated AI Processing Worker - Background Intelligence
  - type: worker
    name: xmrt-ai-background-processor
    env: python
    region: oregon
    plan: standard
    # THE FIX: Use the same unified requirements file
    buildCommand: "pip install -r requirements.txt"
    startCommand: |
      export WORKER_TYPE=AI_BACKGROUND_PROCESSOR
      python background_worker_script.py # Assumes you move the worker logic to a file
    envVars:
      - key: WORKER_MODE
        value: PRODUCTIVE_AI_PROCESSOR
      - key: OPTIMIZATION_INTERVAL
        value: "120"
      - key: LEARNING_RATE
        value: "HIGH"
      - key: PERFORMANCE_TARGET
        value: "MAXIMUM"

  # Real-time Analytics and Performance Monitor
  - type: web
    name: xmrt-performance-monitor
    env: python
    region: oregon
    plan: starter
    # THE FIX: Use the same unified requirements file
    buildCommand: "pip install -r requirements.txt"
    startCommand: "python performance_dashboard_script.py" # Assumes you move the dashboard logic to a file
    healthCheckPath: /status
    envVars:
      - key: MONITOR_MODE
        value: PRODUCTION_DASHBOARD
      - key: METRICS_COLLECTION
        value: REAL_TIME

  # Conversation Intelligence Cache
  - type: redis
    name: xmrt-conversation-cache
    plan: standard
    region: oregon
    maxmemoryPolicy: allkeys-lru

# Production Database for Learning and Analytics
databases:
  - name: xmrt-production-db
    plan: standard
    region: oregon

# Custom Production Domains
domains:
  - name: eliza.xmrt.io
    service: xmrt-eliza-production
  - name: dashboard.xmrt.io
    service: xmrt-performance-monitor

# Build filter is preserved
buildFilter:
  paths:
    - advanced_eliza_orchestrator.py
    - background_worker_script.py
    - performance_dashboard_script.py
    - requirements.txt
    - static/**
    - templates/**
  ignoredPaths:
    - "*.md"
    - "tests/**"
    - ".git/**"
    - "docs/**"
