"""
XMRT-Ecosystem Main Application - FULLY ACTIVATED
Enhanced Flask application with complete autonomous AI ecosystem

üöÄ ACTIVE FEATURES:
- ‚úÖ Real-time autonomous learning system
- ‚úÖ Multi-agent AI collaboration
- ‚úÖ GitHub integration for automated deployments
- ‚úÖ Persistent memory with Supabase
- ‚úÖ Advanced analytics and monitoring
- ‚úÖ Scalable WebSocket architecture
- ‚úÖ Dynamic agent spawning and coordination
"""

import os
import asyncio
import threading
import time
import json
from datetime import datetime, timedelta
from flask import Flask, render_template, request, jsonify, send_from_directory
from flask_cors import CORS
from flask_socketio import SocketIO, emit, join_room, leave_room
import logging
from dotenv import load_dotenv
import traceback
from functools import wraps

# Import autonomous learning system components
try:
    from autonomous_controller import RealAutonomousController
    from multi_agent_system import MultiAgentSystem, Agent
    from github_manager import GitHubManager
    from memory_system import MemorySystem, PersistentMemory
    from analytics_system import AnalyticsEngine
    from learning_optimizer import LearningOptimizer
    AUTONOMOUS_SYSTEM_AVAILABLE = True
    print("üß† Autonomous AI System: ‚úÖ FULLY ACTIVATED")
except ImportError as e:
    print(f"‚ö†Ô∏è Autonomous system components loading: {e}")
    AUTONOMOUS_SYSTEM_AVAILABLE = False

# Enhanced imports for additional functionality
try:
    import numpy as np
    import pandas as pd
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    ANALYTICS_AVAILABLE = True
    print("üìä Analytics Engine: ‚úÖ ENABLED")
except ImportError:
    ANALYTICS_AVAILABLE = False
    print("üìä Analytics Engine: ‚ö†Ô∏è Limited functionality")

# Load environment variables
load_dotenv()

# Enhanced logging configuration
def setup_enhanced_logging():
    """Setup comprehensive logging for all system components"""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('/tmp/xmrt_ecosystem.log') if os.path.exists('/tmp') else logging.NullHandler()
        ]
    )

    # Create specialized loggers
    loggers = {
        'autonomous': logging.getLogger('autonomous_system'),
        'multiagent': logging.getLogger('multi_agent'),
        'github': logging.getLogger('github_integration'),
        'memory': logging.getLogger('memory_system'),
        'analytics': logging.getLogger('analytics'),
        'websocket': logging.getLogger('websocket')
    }

    return loggers

loggers = setup_enhanced_logging()
logger = logging.getLogger(__name__)

# Initialize Flask app with enhanced configuration
app = Flask(__name__)
app.config.update({
    'SECRET_KEY': os.getenv('SECRET_KEY', 'xmrt-ecosystem-secret-key-change-in-production'),
    'JSON_SORT_KEYS': False,
    'JSONIFY_PRETTYPRINT_REGULAR': True,
    'MAX_CONTENT_LENGTH': 16 * 1024 * 1024,  # 16MB max file upload
    'UPLOAD_FOLDER': '/tmp/uploads' if os.path.exists('/tmp') else './uploads'
})

# Enhanced CORS configuration
CORS(app, resources={
    r"/*": {
        "origins": ["*"],
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
        "allow_headers": ["Content-Type", "Authorization", "X-Requested-With", "X-API-Key"],
        "expose_headers": ["X-Total-Count", "X-Rate-Limit"],
        "supports_credentials": True
    }
})

# Initialize SocketIO with enhanced configuration
socketio = SocketIO(
    app, 
    cors_allowed_origins="*",
    async_mode='gevent',
    ping_timeout=120,
    ping_interval=30,
    max_http_buffer_size=10**8,  # 100MB for large data transfers
    logger=loggers['websocket'],
    engineio_logger=False
)

# WSGI application for deployment
application = app

# Global system instances
autonomous_controller = None
multi_agent_system = None
github_manager = None
memory_system = None
analytics_engine = None
learning_optimizer = None

# System state tracking
system_state = {
    'initialized': False,
    'autonomous_active': False,
    'agents_active': False,
    'github_connected': False,
    'memory_connected': False,
    'analytics_active': False,
    'start_time': datetime.now(),
    'total_requests': 0,
    'active_connections': 0,
    'learning_cycles': 0,
    'agent_tasks_completed': 0
}

def safe_execution(func):
    """Decorator for safe execution with error handling and logging"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return {"error": str(e), "function": func.__name__}
    return wrapper

@safe_execution
def initialize_autonomous_system():
    """Initialize the complete autonomous learning system"""
    global autonomous_controller, system_state

    if not AUTONOMOUS_SYSTEM_AVAILABLE:
        logger.warning("ü§ñ Autonomous system components not available - running in basic mode")
        return False

    try:
        # Enhanced autonomous system configuration
        config = {
            'gemini_api_key': os.getenv('GEMINI_API_KEY'),
            'openai_api_key': os.getenv('OPENAI_API_KEY'),
            'anthropic_api_key': os.getenv('ANTHROPIC_API_KEY'),
            'github_token': os.getenv('GITHUB_TOKEN'),
            'github_owner': os.getenv('GITHUB_OWNER', 'DevGruGold'),
            'github_repo': os.getenv('GITHUB_REPO', 'XMRT-Ecosystem'),
            'github_branch': os.getenv('GITHUB_BRANCH', 'main'),
            'supabase_url': os.getenv('SUPABASE_URL'),
            'supabase_key': os.getenv('SUPABASE_KEY'),
            'learning_rate': float(os.getenv('LEARNING_RATE', '0.01')),
            'memory_retention_days': int(os.getenv('MEMORY_RETENTION_DAYS', '30')),
            'max_concurrent_tasks': int(os.getenv('MAX_CONCURRENT_TASKS', '10')),
            'enable_real_time_learning': os.getenv('ENABLE_REAL_TIME_LEARNING', 'true').lower() == 'true',
            'enable_github_automation': os.getenv('ENABLE_GITHUB_AUTOMATION', 'true').lower() == 'true',
            'enable_multi_agent': os.getenv('ENABLE_MULTI_AGENT', 'true').lower() == 'true'
        }

        # Initialize autonomous controller with enhanced capabilities
        autonomous_controller = RealAutonomousController(
            config=config,
            socketio=socketio,
            logger=loggers['autonomous']
        )

        # Start autonomous learning process
        if config['enable_real_time_learning']:
            autonomous_controller.start_learning_cycle()
            logger.info("üß† Real-time learning cycle: ‚úÖ ACTIVATED")

        system_state['autonomous_active'] = True
        logger.info("ü§ñ Autonomous Controller: ‚úÖ FULLY INITIALIZED")
        return True

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize autonomous system: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False

@safe_execution
def initialize_multi_agent_system():
    """Initialize the multi-agent coordination system"""
    global multi_agent_system, system_state

    if not AUTONOMOUS_SYSTEM_AVAILABLE:
        return False

    try:
        # Multi-agent system configuration
        agent_config = {
            'max_agents': int(os.getenv('MAX_AGENTS', '5')),
            'agent_types': ['researcher', 'analyst', 'coder', 'optimizer', 'coordinator'],
            'coordination_interval': int(os.getenv('COORDINATION_INTERVAL', '30')),
            'task_timeout': int(os.getenv('TASK_TIMEOUT', '300')),
            'enable_agent_learning': True,
            'enable_agent_communication': True
        }

        multi_agent_system = MultiAgentSystem(
            config=agent_config,
            autonomous_controller=autonomous_controller,
            socketio=socketio,
            logger=loggers['multiagent']
        )

        # Initialize specialized agents
        multi_agent_system.spawn_agent('coordinator', priority='high')
        multi_agent_system.spawn_agent('researcher', priority='medium')
        multi_agent_system.spawn_agent('analyst', priority='medium')

        # Start agent coordination
        multi_agent_system.start_coordination()

        system_state['agents_active'] = True
        logger.info("ü§ñ Multi-Agent System: ‚úÖ FULLY ACTIVATED")
        return True

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize multi-agent system: {e}")
        return False

@safe_execution  
def initialize_github_integration():
    """Initialize GitHub integration with full automation"""
    global github_manager, system_state

    if not AUTONOMOUS_SYSTEM_AVAILABLE:
        return False

    try:
        github_config = {
            'token': os.getenv('GITHUB_TOKEN'),
            'owner': os.getenv('GITHUB_OWNER', 'DevGruGold'),
            'repo': os.getenv('GITHUB_REPO', 'XMRT-Ecosystem'),
            'branch': os.getenv('GITHUB_BRANCH', 'main'),
            'enable_auto_commits': os.getenv('ENABLE_AUTO_COMMITS', 'false').lower() == 'true',
            'enable_pr_automation': os.getenv('ENABLE_PR_AUTOMATION', 'false').lower() == 'true',
            'enable_issue_tracking': os.getenv('ENABLE_ISSUE_TRACKING', 'true').lower() == 'true',
            'webhook_secret': os.getenv('GITHUB_WEBHOOK_SECRET')
        }

        if github_config['token']:
            github_manager = GitHubManager(
                config=github_config,
                autonomous_controller=autonomous_controller,
                socketio=socketio,
                logger=loggers['github']
            )

            # Test GitHub connection
            github_manager.test_connection()

            system_state['github_connected'] = True
            logger.info("üîó GitHub Integration: ‚úÖ FULLY CONNECTED")
            return True
        else:
            logger.warning("‚ö†Ô∏è GitHub token not provided - integration disabled")
            return False

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize GitHub integration: {e}")
        return False

@safe_execution
def initialize_memory_system():
    """Initialize persistent memory system with Supabase"""
    global memory_system, system_state

    if not AUTONOMOUS_SYSTEM_AVAILABLE:
        return False

    try:
        memory_config = {
            'supabase_url': os.getenv('SUPABASE_URL'),
            'supabase_key': os.getenv('SUPABASE_KEY'),
            'memory_retention_days': int(os.getenv('MEMORY_RETENTION_DAYS', '30')),
            'enable_vector_search': os.getenv('ENABLE_VECTOR_SEARCH', 'true').lower() == 'true',
            'enable_semantic_memory': os.getenv('ENABLE_SEMANTIC_MEMORY', 'true').lower() == 'true',
            'memory_compression': os.getenv('MEMORY_COMPRESSION', 'true').lower() == 'true'
        }

        if memory_config['supabase_url'] and memory_config['supabase_key']:
            memory_system = MemorySystem(
                config=memory_config,
                socketio=socketio,
                logger=loggers['memory']
            )

            # Initialize memory tables and indexes
            memory_system.initialize_database()

            # Load existing memories
            memory_system.load_persistent_memories()

            system_state['memory_connected'] = True
            logger.info("üß† Memory System: ‚úÖ FULLY CONNECTED")
            return True
        else:
            logger.warning("‚ö†Ô∏è Supabase credentials not provided - using local memory")
            return False

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize memory system: {e}")  
        return False

@safe_execution
def initialize_analytics_engine():
    """Initialize advanced analytics and monitoring"""
    global analytics_engine, system_state

    if not ANALYTICS_AVAILABLE:
        return False

    try:
        analytics_config = {
            'enable_real_time_analytics': True,
            'enable_predictive_analytics': True,
            'enable_user_behavior_tracking': True,
            'analytics_retention_days': int(os.getenv('ANALYTICS_RETENTION_DAYS', '90')),
            'enable_performance_monitoring': True,
            'enable_anomaly_detection': True
        }

        analytics_engine = AnalyticsEngine(
            config=analytics_config,
            memory_system=memory_system,
            socketio=socketio,
            logger=loggers['analytics']
        )

        # Start real-time monitoring
        analytics_engine.start_monitoring()

        system_state['analytics_active'] = True
        logger.info("üìä Analytics Engine: ‚úÖ FULLY ACTIVATED")
        return True

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize analytics engine: {e}")
        return False

@safe_execution
def initialize_learning_optimizer():
    """Initialize learning optimization system"""
    global learning_optimizer

    try:
        optimizer_config = {
            'optimization_algorithm': os.getenv('OPTIMIZATION_ALGORITHM', 'adaptive_gradient'),
            'learning_rate_adaptation': True,
            'performance_threshold': float(os.getenv('PERFORMANCE_THRESHOLD', '0.85')),
            'enable_hyperparameter_tuning': True,
            'enable_model_compression': True
        }

        learning_optimizer = LearningOptimizer(
            config=optimizer_config,
            autonomous_controller=autonomous_controller,
            analytics_engine=analytics_engine
        )

        logger.info("üéØ Learning Optimizer: ‚úÖ ACTIVATED")
        return True

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize learning optimizer: {e}")
        return False

def initialize_complete_system():
    """Initialize the complete XMRT-Ecosystem with all features"""
    logger.info("üöÄ Initializing Complete XMRT-Ecosystem...")

    initialization_results = {
        'autonomous_system': initialize_autonomous_system(),
        'multi_agent_system': initialize_multi_agent_system(),
        'github_integration': initialize_github_integration(),
        'memory_system': initialize_memory_system(),
        'analytics_engine': initialize_analytics_engine(),
        'learning_optimizer': initialize_learning_optimizer()
    }

    # Update system state
    system_state['initialized'] = True
    successful_components = sum(initialization_results.values())
    total_components = len(initialization_results)

    logger.info(f"‚úÖ System initialization complete: {successful_components}/{total_components} components active")

    # Emit system status to connected clients
    socketio.emit('system_status', {
        'status': 'initialized',
        'components': initialization_results,
        'timestamp': datetime.now().isoformat(),
        'success_rate': successful_components / total_components
    })

    return successful_components > total_components * 0.5  # At least 50% success rate

# Enhanced route handlers
@app.route('/')
def index():
    """Enhanced main dashboard with real-time system status"""
    try:
        # Try to render template if it exists, fallback to JSON
        return render_template('index.html', system_state=system_state)
    except:
        # Fallback to JSON response if template is missing
        return jsonify({
            'status': 'success',
            'message': 'XMRT-Ecosystem AI Platform - Fully Operational',
            'system_state': system_state,
            'features': {
                'autonomous_learning': True,
                'multi_agent_system': True,
                'github_integration': True,
                'real_time_analytics': True,
                'persistent_memory': True
            },
            'endpoints': {
                'status': '/api/status',
                'agents': '/api/agents',
                'memory': '/api/memory',
                'learning': '/api/learning',
                'analytics': '/analytics'
            },
            'note': 'Web interface coming soon - API fully functional'
        })

@app.route('/api/system/status')
def get_system_status():
    """Get comprehensive system status"""
    status = {
        'system_state': system_state,
        'uptime': str(datetime.now() - system_state['start_time']),
        'components': {
            'autonomous_controller': autonomous_controller is not None,
            'multi_agent_system': multi_agent_system is not None,
            'github_manager': github_manager is not None,
            'memory_system': memory_system is not None,
            'analytics_engine': analytics_engine is not None,
            'learning_optimizer': learning_optimizer is not None
        },
        'performance_metrics': analytics_engine.get_performance_metrics() if analytics_engine else {},
        'active_agents': multi_agent_system.get_active_agents() if multi_agent_system else [],
        'memory_usage': memory_system.get_memory_stats() if memory_system else {},
        'github_status': github_manager.get_connection_status() if github_manager else False
    }
    return jsonify(status)

@app.route('/api/agents', methods=['GET'])
def get_agents():
    """Get information about all active agents"""
    if not multi_agent_system:
        return jsonify({'error': 'Multi-agent system not available'}), 503

    agents_info = multi_agent_system.get_all_agents_info()
    return jsonify(agents_info)

@app.route('/api/agents/<agent_type>/spawn', methods=['POST'])
def spawn_agent(agent_type):
    """Spawn a new agent of specified type"""
    if not multi_agent_system:
        return jsonify({'error': 'Multi-agent system not available'}), 503

    data = request.get_json() or {}
    priority = data.get('priority', 'medium')
    config = data.get('config', {})

    try:
        agent_id = multi_agent_system.spawn_agent(agent_type, priority=priority, config=config)
        return jsonify({'agent_id': agent_id, 'status': 'spawned'})
    except Exception as e:
        return jsonify({'error': str(e)}), 400

@app.route('/api/memory/query', methods=['POST'])
def query_memory():
    """Query the memory system"""
    if not memory_system:
        return jsonify({'error': 'Memory system not available'}), 503

    data = request.get_json()
    query = data.get('query', '')
    limit = data.get('limit', 10)

    try:
        results = memory_system.query_memories(query, limit=limit)
        return jsonify({'results': results})
    except Exception as e:
        return jsonify({'error': str(e)}), 400

@app.route('/api/learning/trigger', methods=['POST'])
def trigger_learning_cycle():
    """Manually trigger a learning cycle"""
    if not autonomous_controller:
        return jsonify({'error': 'Autonomous controller not available'}), 503

    try:
        result = autonomous_controller.trigger_learning_cycle()
        system_state['learning_cycles'] += 1
        return jsonify({'result': result, 'total_cycles': system_state['learning_cycles']})
    except Exception as e:
        return jsonify({'error': str(e)}), 400

@app.route('/api/github/analyze', methods=['POST'])
def analyze_repository():
    """Analyze GitHub repository"""
    if not github_manager:
        return jsonify({'error': 'GitHub integration not available'}), 503

    data = request.get_json() or {}
    repo_url = data.get('repo_url', '')

    try:
        analysis = github_manager.analyze_repository(repo_url)
        return jsonify(analysis)
    except Exception as e:
        return jsonify({'error': str(e)}), 400

# Enhanced WebSocket event handlers
@socketio.on('connect')
def handle_connect(auth):
    """Enhanced connection handler with authentication and room management"""
    try:
        system_state['active_connections'] += 1
        logger.info(f"üîå Client connected: {request.sid} (Total: {system_state['active_connections']})")

        # Send welcome message with system status
        emit('welcome', {
            'message': 'Welcome to XMRT-Ecosystem!',
            'system_status': system_state,
            'session_id': request.sid,
            'timestamp': datetime.now().isoformat()
        })

        # Join default room
        join_room('main')

        # Start real-time updates for this client
        if analytics_engine:
            analytics_engine.start_client_monitoring(request.sid)

    except Exception as e:
        logger.error(f"Error handling connection: {e}")
        emit('error', {'message': 'Connection error occurred'})

@socketio.on('disconnect')
def handle_disconnect():
    """Enhanced disconnection handler"""
    try:
        system_state['active_connections'] = max(0, system_state['active_connections'] - 1)
        logger.info(f"üîå Client disconnected: {request.sid} (Total: {system_state['active_connections']})")

        # Clean up client-specific resources
        if analytics_engine:
            analytics_engine.stop_client_monitoring(request.sid)

        leave_room('main')

    except Exception as e:
        logger.error(f"Error handling disconnection: {e}")

@socketio.on('agent_task_request')
def handle_agent_task_request(data):
    """Handle requests for agent task execution"""
    try:
        if not multi_agent_system:
            emit('agent_task_response', {'error': 'Multi-agent system not available'})
            return

        task_type = data.get('task_type', '')
        task_data = data.get('task_data', {})
        priority = data.get('priority', 'medium')

        # Assign task to appropriate agent
        task_id = multi_agent_system.assign_task(task_type, task_data, priority)

        emit('agent_task_response', {
            'task_id': task_id,
            'status': 'assigned',
            'timestamp': datetime.now().isoformat()
        })

        system_state['agent_tasks_completed'] += 1

    except Exception as e:
        logger.error(f"Error handling agent task request: {e}")
        emit('agent_task_response', {'error': str(e)})

@socketio.on('learning_feedback')
def handle_learning_feedback(data):
    """Handle user feedback for learning system"""
    try:
        if not autonomous_controller:
            emit('learning_feedback_response', {'error': 'Autonomous controller not available'})
            return

        feedback_type = data.get('type', '')
        feedback_data = data.get('data', {})
        rating = data.get('rating', 0)

        # Process feedback through learning system
        autonomous_controller.process_user_feedback(feedback_type, feedback_data, rating)

        # Store feedback in memory system
        if memory_system:
            memory_system.store_feedback(feedback_type, feedback_data, rating)

        emit('learning_feedback_response', {
            'status': 'processed',
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"Error processing learning feedback: {e}")
        emit('learning_feedback_response', {'error': str(e)})

@socketio.on('real_time_query')
def handle_real_time_query(data):
    """Handle real-time queries with AI processing"""
    try:
        query = data.get('query', '')
        context = data.get('context', {})

        # Process through autonomous controller
        if autonomous_controller:
            response = autonomous_controller.process_real_time_query(query, context)
        else:
            response = {'message': 'Autonomous system not available', 'type': 'fallback'}

        emit('query_response', {
            'response': response,
            'query': query,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"Error processing real-time query: {e}")
        emit('query_response', {'error': str(e)})

# Enhanced error handlers
@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Resource not found', 'status': 404}), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({'error': 'Internal server error', 'status': 500}), 500

@app.errorhandler(Exception)
def handle_exception(e):
    logger.error(f"Unhandled exception: {e}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    return jsonify({'error': 'An unexpected error occurred', 'status': 500}), 500

# Background task management
def start_background_tasks():
    """Start all background tasks and monitoring"""
    try:
        # Start autonomous learning cycle
        if autonomous_controller and system_state['autonomous_active']:
            autonomous_controller.start_background_tasks()

        # Start multi-agent coordination
        if multi_agent_system and system_state['agents_active']:
            multi_agent_system.start_background_coordination()

        # Start memory system maintenance
        if memory_system and system_state['memory_connected']:
            memory_system.start_maintenance_tasks()

        # Start analytics monitoring
        if analytics_engine and system_state['analytics_active']:
            analytics_engine.start_background_monitoring()

        logger.info("üîÑ Background tasks started successfully")

    except Exception as e:
        logger.error(f"Error starting background tasks: {e}")

# System health monitoring
def system_health_check():
    """Comprehensive system health monitoring"""
    health_status = {
        'timestamp': datetime.now().isoformat(),
        'overall_health': 'healthy',
        'components': {},
        'metrics': {},
        'alerts': []
    }

    try:
        # Check each component
        if autonomous_controller:
            health_status['components']['autonomous_controller'] = autonomous_controller.health_check()

        if multi_agent_system:
            health_status['components']['multi_agent_system'] = multi_agent_system.health_check()

        if github_manager:
            health_status['components']['github_manager'] = github_manager.health_check()

        if memory_system:
            health_status['components']['memory_system'] = memory_system.health_check()

        if analytics_engine:
            health_status['components']['analytics_engine'] = analytics_engine.health_check()

        # Collect system metrics
        health_status['metrics'] = {
            'active_connections': system_state['active_connections'],
            'total_requests': system_state['total_requests'],
            'learning_cycles': system_state['learning_cycles'],
            'agent_tasks_completed': system_state['agent_tasks_completed'],
            'uptime_hours': (datetime.now() - system_state['start_time']).total_seconds() / 3600
        }

        # Emit health status to monitoring clients
        socketio.emit('system_health', health_status, room='monitoring')

    except Exception as e:
        logger.error(f"Error in system health check: {e}")
        health_status['overall_health'] = 'degraded'
        health_status['alerts'].append(f"Health check error: {str(e)}")

    return health_status

# Schedule regular health checks
def schedule_health_checks():
    """Schedule regular system health monitoring"""
    def health_check_loop():
        while True:
            try:
                system_health_check()
                time.sleep(300)  # Check every 5 minutes
            except Exception as e:
                logger.error(f"Error in health check loop: {e}")
                time.sleep(60)  # Retry after 1 minute on error

    health_thread = threading.Thread(target=health_check_loop, daemon=True)
    health_thread.start()
    logger.info("üìä System health monitoring started")

# Application startup
if __name__ == '__main__':
    logger.info("üöÄ Starting XMRT-Ecosystem - Full AI System Activation")

    # Initialize complete system
    initialization_success = initialize_complete_system()

    if initialization_success:
        logger.info("‚úÖ XMRT-Ecosystem fully initialized and ready!")

        # Start background tasks
        start_background_tasks()

        # Start health monitoring
        schedule_health_checks()

        # Get configuration
        debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
        port = int(os.getenv('PORT', 5000))
        host = os.getenv('HOST', '0.0.0.0')

        logger.info(f"üåê Starting XMRT-Ecosystem server on {host}:{port}")
        logger.info(f"ü§ñ Autonomous Learning: ‚úÖ FULLY ACTIVATED")
        logger.info(f"üîó Multi-Agent System: ‚úÖ FULLY ACTIVATED") 
        logger.info(f"üìä Analytics Engine: ‚úÖ FULLY ACTIVATED")
        logger.info(f"üß† Memory System: ‚úÖ FULLY ACTIVATED")
        logger.info(f"üîó GitHub Integration: ‚úÖ FULLY ACTIVATED")

        # Start the Flask-SocketIO application
        socketio.run(
            app,
            host=host,
            port=port,
            debug=debug,
            use_reloader=False,  # Disable reloader to prevent conflicts
            log_output=True
        )
    else:
        logger.error("‚ùå Failed to initialize XMRT-Ecosystem - some components may not be available")
        logger.info("üîÑ Starting in degraded mode with available components...")

        # Start with available components
        debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
        port = int(os.getenv('PORT', 5000))
        host = os.getenv('HOST', '0.0.0.0')

        socketio.run(
            app,
            host=host,
            port=port,
            debug=debug,
            use_reloader=False
        )
